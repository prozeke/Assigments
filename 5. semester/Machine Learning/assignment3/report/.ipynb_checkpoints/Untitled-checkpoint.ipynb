{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "## Part 1\n",
    "### Theory Questions\n",
    "    1) What are the diffrences between logistic regression and linear regression?\n",
    "            \n",
    "            Linear regression is for continous problems whereas logistic regression is a classifier.\n",
    "        Logistic regression is a probabilistic approach. It calculates the probabilities of each class and tries to minimize\n",
    "        its error. Linear regression is an analaytic approach. It tries to find a line that is fits best to the data points.\n",
    "        This approaches results different objective functions. Logistic regression uses cross-entropy error function and\n",
    "        linear regression uses mean squared error function.\n",
    "        \n",
    "    2)What are differences between logistic regression and naive bayes methods?\n",
    "           \n",
    "           Logistic regression tries to find posterior directly. This makes logistic regression a discriminitive model.\n",
    "        Naive bayes first finds prior probability for each feature. Then, with the assumption of conditional independency\n",
    "        of each variable, it finds posterior. This makes naive bayes a generative model.\n",
    "            Naive bayes reaches to its asymptotic error faster. However, logistic regression ha a lower asymptotic error.\n",
    "        This makes naive bayes a better algorithm for small datasets and makes logistic regression better for large datasets.\n",
    "            As mentioned above, naive bayes makes the assumption of marginally conditionally independence for every feature\n",
    "        Another diffrence is that logistic regression does not have such an assumption.\n",
    "\n",
    "    3)Which of the following statements are true?\n",
    "        \n",
    "        True ones are:\n",
    "                A two layer (one input layer, one output layer; no hidden layer) neural network\n",
    "            can represent the XOR function.\n",
    "            \n",
    "                Any logical function over binary-valued (0 or 1) inputs x 1 andx 2 can be\n",
    "            (approximately) represented using some neural network.\n",
    "                \n",
    "                The activation values of the hidden units in a neural network, with the sigmoid\n",
    "            activation function applied at every layer, are always in the range (0, 1).\n",
    "            It is hard to say anything on the last one. Activation values of the hidden units does not needs to be\n",
    "            neccesarily between (0,1). But when application function is applied to activasions, outputs would range\n",
    "            between(0,1). I added this one as true too because I didn't understand which one was asking.\n",
    "            \n",
    "    4)How to decide the number of hidden layers and nodes in a hidden layer?\n",
    "        \n",
    "        They say that, in most cases, 1 hidden layer is sufdicent enough. The number of neurons in one layer should be\n",
    "    between the output class size and feauture size.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Classification of Flowers using Neural Networks\n",
    "### Owerview of the Problem\n",
    "        Neural networks can express many data distributions. In this homework, we are expected to construct neural network to classify five class\n",
    "    of flowers. First, we will implement a single layer neural network. Then, we extend the neural network to a multilayer network.\n",
    "### Data Set\n",
    "        We will use this https://www.kaggle.com/alxmamaev/flowers-recognition/downloads/flowers.zip/1 dataset. In addition to that\n",
    "    Necva Bölücü hoca shared a code that converts pictures to vectors with 768 features. I have used that vectors as inputs.\n",
    "\n",
    "### Algorithm\n",
    "        Neural networks consists of layers. Each layer has an activation function and some number of neurons. Each neuron has a weight vector.\n",
    "    In addition to that, a neural network has an objective function. The goal of training is to minimize objective function.\n",
    "    It is really import to know the overall structure of a neural network in order to understand the algorithm. \n",
    "    \n",
    "        The training algorithm has two main parts. These parts are feed forward and back propagation.We use these parts consecutively in order\n",
    "    to update the weights of each neuron. We first feed forward, and then back propagete to find derivatives.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"network.png\" width=\"1000\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feed Forward\n",
    "&emsp; For each layer, one forward is finding the input of the next layer, with respect to its weights and activation function.\n",
    "&emsp;Lets suppose that we are at layer j and find the inputs of the next layer. $w_{ji}$ denotes the i'th neurons weight vector and $z_j$ is the inputs<br>\n",
    "of the the j'th layer and $z_{ki}$ is the i'th input of the next layer. $h_j()$ is j'th layers activation. Then one forward means finding the $z_k$ vector.<br>\n",
    "$z_kj = h_j(z_j^T.w_{ji})$\n",
    "&emps;Finding the inputs f each layer is feed forward. At last layer, we find the inputs of the error function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back Propagation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
